{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "100396aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 503 S&P 500 tickers.\n",
      "Downloading data for tickers 1 to 100...\n",
      "YF.download() has changed argument auto_adjust default to True\n",
      "Downloading data for tickers 101 to 200...\n",
      "Downloading data for tickers 201 to 300...\n",
      "Downloading data for tickers 301 to 400...\n",
      "Downloading data for tickers 401 to 500...\n",
      "Downloading data for tickers 501 to 503...\n",
      "Retrieved daily data from 2025-01-22 to 2025-04-22.\n",
      "Data shape: (62, 503)\n",
      "Calculated daily advances and declines.\n",
      "            Advances  Declines  Unchanged  Total  Advance_Decline_Diff\n",
      "Date                                                                  \n",
      "2025-01-22         0         0          0      0                     0\n",
      "2025-01-23       326       173          4    503                   153\n",
      "2025-01-24       251       246          6    503                     5\n",
      "2025-01-27       348       155          0    503                   193\n",
      "2025-01-28       154       346          3    503                  -192\n",
      "Data saved to CSV files\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "def get_sp500_tickers():\n",
    "    \"\"\"\n",
    "    Retrieves current S&P 500 components from Wikipedia\n",
    "    \n",
    "    Returns:\n",
    "        list: List of S&P 500 ticker symbols\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # URL for the S&P 500 components table on Wikipedia\n",
    "        url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "        \n",
    "        # Read the tables from the Wikipedia page\n",
    "        tables = pd.read_html(url)\n",
    "        \n",
    "        # The first table contains the S&P 500 components\n",
    "        sp500_table = tables[0]\n",
    "        \n",
    "        # Extract the 'Symbol' column as a list\n",
    "        tickers = sp500_table['Symbol'].tolist()\n",
    "        \n",
    "        # Clean up the tickers (replace dots with hyphens for BRK.B, etc.)\n",
    "        tickers = [ticker.replace('.', '-') for ticker in tickers]\n",
    "        \n",
    "        return tickers\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving S&P 500 tickers: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_daily_data(tickers, start_date='2020-01-01', end_date=None, batch_size=100):\n",
    "    \"\"\"\n",
    "    Retrieves daily price data for a list of tickers in batches to avoid API limitations\n",
    "    \n",
    "    Args:\n",
    "        tickers (list): List of ticker symbols\n",
    "        start_date (str): Start date for data retrieval in YYYY-MM-DD format\n",
    "        end_date (str): End date for data retrieval in YYYY-MM-DD format\n",
    "        batch_size (int): Number of tickers to download at once\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with daily closing prices for each ticker\n",
    "    \"\"\"\n",
    "    if end_date is None:\n",
    "        end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "    all_data = pd.DataFrame()\n",
    "    \n",
    "    # Process tickers in batches to avoid API limitations\n",
    "    for i in range(0, len(tickers), batch_size):\n",
    "        batch_tickers = tickers[i:i+batch_size]\n",
    "        print(f\"Downloading data for tickers {i+1} to {min(i+batch_size, len(tickers))}...\")\n",
    "        \n",
    "        try:\n",
    "            # Download daily data for the batch\n",
    "            batch_data = yf.download(batch_tickers, start=start_date, end=end_date, progress=False)\n",
    "            \n",
    "            # If we have more than one ticker, we'll have a MultiIndex DataFrame\n",
    "            if len(batch_tickers) > 1:\n",
    "                batch_close = batch_data['Close']\n",
    "            else:\n",
    "                # For a single ticker, we need to handle differently\n",
    "                batch_close = batch_data['Close'].to_frame(name=batch_tickers[0])\n",
    "            \n",
    "            # For the first batch, set this as our dataframe\n",
    "            if all_data.empty:\n",
    "                all_data = batch_close\n",
    "            else:\n",
    "                # For subsequent batches, join with existing data\n",
    "                all_data = all_data.join(batch_close, how='outer')\n",
    "            \n",
    "            # Add a small delay to avoid hitting API limits\n",
    "            time.sleep(1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading data for batch starting at index {i}: {e}\")\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "def calculate_daily_advances_declines(daily_data):\n",
    "    \"\"\"\n",
    "    Calculate the number of advancing and declining stocks each day\n",
    "    \n",
    "    Args:\n",
    "        daily_data (pd.DataFrame): DataFrame with daily closing prices for each ticker\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with daily counts of advances, declines, and unchanged\n",
    "    \"\"\"\n",
    "    # Calculate daily price changes\n",
    "    daily_changes = daily_data.pct_change()\n",
    "    \n",
    "    # Count advances, declines, and unchanged for each day\n",
    "    advances = (daily_changes > 0).sum(axis=1)\n",
    "    declines = (daily_changes < 0).sum(axis=1)\n",
    "    unchanged = (daily_changes == 0).sum(axis=1)\n",
    "    \n",
    "    # Create DataFrame with results\n",
    "    breadth_data = pd.DataFrame({\n",
    "        'Advances': advances,\n",
    "        'Declines': declines,\n",
    "        'Unchanged': unchanged,\n",
    "        'Total': advances + declines + unchanged,\n",
    "        'Advance_Decline_Diff': advances - declines\n",
    "    })\n",
    "    \n",
    "    return breadth_data\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Get S&P 500 tickers\n",
    "    sp500_tickers = get_sp500_tickers()\n",
    "    print(f\"Retrieved {len(sp500_tickers)} S&P 500 tickers.\")\n",
    "    \n",
    "    # Get daily data for the last 90 days (adjust timeframe as needed)\n",
    "    end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "    start_date = (datetime.today() - timedelta(days=90)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    daily_data = get_daily_data(sp500_tickers, start_date, end_date)\n",
    "    print(f\"Retrieved daily data from {start_date} to {end_date}.\")\n",
    "    print(f\"Data shape: {daily_data.shape}\")\n",
    "    \n",
    "    # Calculate daily advances and declines\n",
    "    breadth_data = calculate_daily_advances_declines(daily_data)\n",
    "    print(\"Calculated daily advances and declines.\")\n",
    "    print(breadth_data.head())\n",
    "    \n",
    "    # Save the data to CSV files for future use\n",
    "    daily_data.to_csv('sp500_daily_prices.csv')\n",
    "    breadth_data.to_csv('sp500_breadth_data.csv')\n",
    "    print(\"Data saved to CSV files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trader_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
