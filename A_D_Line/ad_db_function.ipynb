{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33c10d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running NYSE breadth analysis from 2018-01-01 to 2025-04-23...\n",
      "Retrieved 2356 clean NYSE ticker symbols\n",
      "Downloading data for tickers 1 to 500...\n",
      "Downloading data for tickers 501 to 1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3 Failed downloads:\n",
      "['EAI']: YFPricesMissingError('possibly delisted; no price data found  (1d 2018-01-01 -> 2025-04-23)')\n",
      "['ECC           ', 'ETX           ']: YFPricesMissingError('possibly delisted; no price data found  (1d 2018-01-01 -> 2025-04-23) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for tickers 1001 to 1500...\n",
      "Downloading data for tickers 1501 to 2000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2 Failed downloads:\n",
      "['SFB']: YFPricesMissingError('possibly delisted; no price data found  (1d 2018-01-01 -> 2025-04-23)')\n",
      "['SAND          ']: YFPricesMissingError('possibly delisted; no price data found  (1d 2018-01-01 -> 2025-04-23) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for tickers 2001 to 2356...\n",
      "Downloaded daily price data with shape (1836, 2356)\n",
      "Successfully exported breadth data to nyse_breadth_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0l/68dwwf7n4k14jjgryv9tt5mw0000gn/T/ipykernel_27623/952589310.py:70: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  daily_changes = all_data.pct_change()\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def get_nyse_breadth_data(start_date, end_date, csv_file_path='NYSE.csv', export_path='nyse_breadth_data.csv'):\n",
    "    \"\"\"\n",
    "    Retrieves NYSE ticker data, calculates daily advances/declines/neutral,\n",
    "    and exports the data to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format\n",
    "        csv_file_path (str): Path to the NYSE tickers CSV file\n",
    "        export_path (str): Path for the output CSV file\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with daily advances, declines, and neutral counts\n",
    "    \"\"\"\n",
    "    print(f\"Running NYSE breadth analysis from {start_date} to {end_date}...\")\n",
    "    \n",
    "    # Step 1: Retrieve NYSE tickers\n",
    "    try:\n",
    "        nyse_data = pd.read_csv(csv_file_path)\n",
    "        tickers = nyse_data['Symbol'].tolist()\n",
    "        \n",
    "        # Clean tickers for yfinance\n",
    "        clean_tickers = []\n",
    "        for ticker in tickers:\n",
    "            ticker_str = str(ticker)\n",
    "            if not re.search(r'[\\^/\\.\\-]', ticker_str):\n",
    "                clean_tickers.append(ticker_str)\n",
    "        \n",
    "        print(f\"Retrieved {len(clean_tickers)} clean NYSE ticker symbols\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving NYSE tickers: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Get daily price data in batches\n",
    "    batch_size = 500\n",
    "    all_data = pd.DataFrame()\n",
    "    \n",
    "    for i in range(0, len(clean_tickers), batch_size):\n",
    "        batch_tickers = clean_tickers[i:i+batch_size]\n",
    "        print(f\"Downloading data for tickers {i+1} to {min(i+batch_size, len(clean_tickers))}...\")\n",
    "        \n",
    "        try:\n",
    "            batch_data = yf.download(batch_tickers, start=start_date, end=end_date, progress=False)\n",
    "            \n",
    "            if len(batch_tickers) > 1:\n",
    "                batch_close = batch_data['Close']\n",
    "            else:\n",
    "                batch_close = batch_data['Close'].to_frame(name=batch_tickers[0])\n",
    "            \n",
    "            if all_data.empty:\n",
    "                all_data = batch_close\n",
    "            else:\n",
    "                all_data = all_data.join(batch_close, how='outer')\n",
    "            \n",
    "            time.sleep(1)  # Avoid hitting API limits\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading data for batch starting at index {i}: {e}\")\n",
    "    \n",
    "    print(f\"Downloaded daily price data with shape {all_data.shape}\")\n",
    "    \n",
    "    # Step 3: Calculate daily advances, declines, and neutral\n",
    "    daily_changes = all_data.pct_change()\n",
    "    \n",
    "    advances = (daily_changes > 0).sum(axis=1)\n",
    "    declines = (daily_changes < 0).sum(axis=1)\n",
    "    neutral = (daily_changes == 0).sum(axis=1)\n",
    "    \n",
    "    # Create DataFrame with results\n",
    "    breadth_data = pd.DataFrame({\n",
    "        'Advancers': advances,\n",
    "        'Decliners': declines,\n",
    "        'Neutral': neutral\n",
    "    })\n",
    "    \n",
    "    # Drop the first row which has all zeros due to no percentage change calculation\n",
    "    breadth_data = breadth_data.iloc[1:]\n",
    "    # Step 4: Export to CSV\n",
    "    try:\n",
    "        breadth_data.to_csv(export_path)\n",
    "        print(f\"Successfully exported breadth data to {export_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting data to CSV: {e}\")\n",
    "    \n",
    "    return breadth_data\n",
    "\n",
    "# Example usage:\n",
    "breadth_data = get_nyse_breadth_data('2018-01-01', '2025-04-23', 'NYSE.csv', 'nyse_breadth_2023.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trader_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
